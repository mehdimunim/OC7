
# DONE

- Sauvegarder le vectorizer / prétraitement pour utiliser dans l'API

- Ajouter paramètre nom sur reduce_dim

- Faire fonctionner l'API Flask

- AJouter un Embedding dans le LSTM avec Word2vec
model.add_layer(Embedding...)

- Utiliser MFlow dans tous les modèles
Empaqueter tous dans MFlow (with MLFlow)

- LSTM avec Fasttext

- Optimisation du LSTM

- TOC + Structure (jupyterlab)

- Récupérer les metrics des données

- Tableau comparatif 

- Faire fonctionner BERT (1% des données).
Faire via le evaluate_model (cf fleuryc)


- Améliorer les performances des modèles LSTM


- Relancer les modèles sur 10% des données

- pipeline d’entraînement des modèles reproductible

- sérialisé et stocké les modèles créés dans un registre centralisé afin de pouvoir facilement les réutiliser.

- formalisé des mesures et résultats de chaque expérimentation, afin de les analyser et de les comparer


- Setup d'un compte pythonanywhere

- Relancer BERT sur 1% des données

- déployé le modèle de machine learning sous forme d'API (via Flask par exemple) et cette API renvoie bien une prédiction correspondant à une demande. 

- Pipleine de déploiement continu 

- Tests unitaires automatisés

- Réalisation de l'API

- Réalisation notebook avec widget pour la prédiction


# TODO

- CloudWatch ==> lancement d'une alerte email au bout de 3 erreurs

- Rédaction article blog

- Réaliser la présentation

- Rerédiger au propre le README.md (requirements, how to launch etc.)


