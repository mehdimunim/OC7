{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des données de tweets\n",
    "\n",
    "**Auteur :** Mehdi MUNIM\n",
    "\n",
    "**Date :** 2023-11-26\n",
    "\n",
    "**Description :**\n",
    "\n",
    "Ce notebook prétraite les données de tweets en utilisant les fonctions définies dans le fichier `preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Importation des librairies\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Ajouter le chemin du dossier src pour importer les modules\n",
    "sys.path.append('../src')\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premières lignes du DataFrame :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title 2.1 Chargement des données\n",
    "\n",
    "# Charger les données du fichier CSV\n",
    "df = pd.read_csv('../data/raw/training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)\n",
    "\n",
    "# Renommer les colonnes\n",
    "df.columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "print(\"Premières lignes du DataFrame :\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Échantillonage des données\n",
    "\n",
    "# Mélanger les données\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Échantillonner 10 % des données\n",
    "df = df.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premières lignes du DataFrame avec les tweets nettoyés :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480874</th>\n",
       "      <td>0</td>\n",
       "      <td>2179423207</td>\n",
       "      <td>Mon Jun 15 09:05:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>fashionNERD</td>\n",
       "      <td>internet slow today like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352277</th>\n",
       "      <td>4</td>\n",
       "      <td>2046335842</td>\n",
       "      <td>Fri Jun 05 12:01:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SLmoore</td>\n",
       "      <td>hammer everything look like nail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409163</th>\n",
       "      <td>0</td>\n",
       "      <td>2059580298</td>\n",
       "      <td>Sat Jun 06 17:13:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ashleyiswhatsup</td>\n",
       "      <td>kid crazy save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796992</th>\n",
       "      <td>0</td>\n",
       "      <td>2327988448</td>\n",
       "      <td>Thu Jun 25 09:02:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>peachtweet</td>\n",
       "      <td>puppy libby scratched heel bleeding got bandaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814154</th>\n",
       "      <td>4</td>\n",
       "      <td>1550733689</td>\n",
       "      <td>Sat Apr 18 07:05:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mchollee</td>\n",
       "      <td>okay ipod synced finally happy anywho painting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "480874           0  2179423207  Mon Jun 15 09:05:02 PDT 2009  NO_QUERY   \n",
       "1352277          4  2046335842  Fri Jun 05 12:01:59 PDT 2009  NO_QUERY   \n",
       "409163           0  2059580298  Sat Jun 06 17:13:08 PDT 2009  NO_QUERY   \n",
       "796992           0  2327988448  Thu Jun 25 09:02:03 PDT 2009  NO_QUERY   \n",
       "814154           4  1550733689  Sat Apr 18 07:05:59 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "480874       fashionNERD                           internet slow today like  \n",
       "1352277          SLmoore                   hammer everything look like nail  \n",
       "409163   Ashleyiswhatsup                                     kid crazy save  \n",
       "796992        peachtweet    puppy libby scratched heel bleeding got bandaid  \n",
       "814154          mchollee  okay ipod synced finally happy anywho painting...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title 3.1 Nettoyage du texte\n",
    "\n",
    "# Appliquer la fonction de nettoyage du module preprocessing\n",
    "df['text'] = df['text'].map(lambda tweet: clean_tweet(tweet))\n",
    "\n",
    "# Afficher les premières lignes du DataFrame avec les tweets nettoyés\n",
    "print(\"Premières lignes du DataFrame avec les tweets nettoyés :\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:58:41.269371: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 17:58:44.660348: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 35200000 exceeds 10% of free system memory.\n",
      "2024-11-26 17:58:44.860305: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 35200000 exceeds 10% of free system memory.\n",
      "2024-11-26 17:58:44.982769: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 35200000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "#@title 3.2 Tokenization\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Charger le tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokeniser les tweets\n",
    "X = tokenizer(\n",
    "    df['text'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,  # Spécifier la longueur maximale des séquences\n",
    "    return_tensors=\"tf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Conversion des labels en 0 et 1\n",
    "\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})  # Convertir les labels en 0 et 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.3 Vectorisation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorisation TF-IDF\n",
    "X_train_tfidf, X_test_tfidf = vectorize_tfidf(X_train, X_test)\n",
    "\n",
    "# Vectorisation Word2Vec\n",
    "X_train_w2v, X_test_w2v = vectorize_word2vec(X_train, X_test)\n",
    "\n",
    "# Vectorisation Doc2Vec\n",
    "X_train_d2v, X_test_d2v = vectorize_doc2vec(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.4 Réduction de dimensionnalité\n",
    "\n",
    "# Réduction de dimensionnalité pour TF-IDF\n",
    "X_train_tfidf, X_test_tfidf = reduce_dimensionality(X_train_tfidf, X_test_tfidf, y_train, k=1000)\n",
    "\n",
    "# Réduction de dimensionnalité pour Word2Vec\n",
    "X_train_w2v, X_test_w2v = reduce_dimensionality(X_train_w2v, X_test_w2v, y_train, k=100)\n",
    "\n",
    "# Réduction de dimensionnalité pour Doc2Vec\n",
    "X_train_d2v, X_test_d2v = reduce_dimensionality(X_train_d2v, X_test_d2v, y_train, k=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sauvegarde des données prétraitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4.1 Sauvegarde des données\n",
    "\n",
    "import os\n",
    "import pickle \n",
    "\n",
    "# Chemin d'accès au dossier data\n",
    "data_path = '../data/processed/'\n",
    "\n",
    "# Créer le dossier s'il n'existe pas\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Sauvegarde des données pour chaque méthode\n",
    "def save_data(X_train, X_test, methode):\n",
    "    with open(data_path + f'X_train_{methode}.pickle', 'wb') as f:\n",
    "        pickle.dump(X_train, f)\n",
    "    with open(data_path + f'X_test_{methode}.pickle', 'wb') as f:\n",
    "        pickle.dump(X_test, f)\n",
    "\n",
    "save_data(X_train_tfidf, X_test_tfidf, \"tfidf\")\n",
    "save_data(X_train_w2v, X_test_w2v, \"word2vec\")\n",
    "save_data(X_train_d2v, X_test_d2v, \"doc2vec\")\n",
    "\n",
    "# Sauvegarde de y_train et y_test\n",
    "with open(data_path + 'y_train.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open(data_path + 'y_test.pickle', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
