{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation et évaluation des modèles\n",
    "\n",
    "**Auteur :** Mehdi MUNIM\n",
    "\n",
    "**Date :** 2023-11-26\n",
    "\n",
    "**Description :**\n",
    "\n",
    "Ce notebook entraîne et évalue différents modèles de Machine Learning pour la classification de sentiment sur les données de tweets prétraitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Importation des librairies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# Ajouter le chemin du dossier src pour importer les modules\n",
    "sys.path.append('../src')\n",
    "import model\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2.1 Chargement des données\n",
    "\n",
    "# Chemin d'accès au dossier data\n",
    "data_path = '../data/processed/'\n",
    "\n",
    "# Charger les données prétraitées\n",
    "X_train_tfidf = pickle.load(open(data_path + 'X_train_tfidf.pickle', 'rb'))\n",
    "X_test_tfidf = pickle.load(open(data_path + 'X_test_tfidf.pickle', 'rb'))\n",
    "X_train_w2v = pickle.load(open(data_path + 'X_train_word2vec.pickle', 'rb'))\n",
    "X_test_w2v = pickle.load(open(data_path + 'X_test_word2vec.pickle', 'rb'))\n",
    "X_train_d2v = pickle.load(open(data_path + 'X_train_doc2vec.pickle', 'rb'))\n",
    "X_test_d2v = pickle.load(open(data_path + 'X_test_doc2vec.pickle', 'rb'))\n",
    "y_train = pickle.load(open(data_path + 'y_train.pickle', 'rb'))\n",
    "y_test = pickle.load(open(data_path + 'y_test.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entraînement et évaluation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.1 Entraînement et évaluation du modèle de régression logistique\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Créer et entraîner le modèle de régression logistique\n",
    "model_lr = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42)\n",
    "model_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Évaluer le modèle\n",
    "evaluation.evaluer_modele(model_lr, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.2 Entraînement et évaluation du modèle MLP\n",
    "\n",
    "# Créer et entraîner le modèle MLP\n",
    "model_mlp = model.create_mlp_model(input_shape=(X_train_tfidf.shape[1],))\n",
    "model_mlp.fit(X_train_tfidf, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle\n",
    "evaluation.evaluer_modele(model_mlp, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.3 Entraînement et évaluation du modèle CNN\n",
    "\n",
    "# Reshape les données pour le modèle CNN\n",
    "X_train_cnn = np.reshape(X_train_w2v, (X_train_w2v.shape[0], X_train_w2v.shape[1], 1))\n",
    "X_test_cnn = np.reshape(X_test_w2v, (X_test_w2v.shape[0], X_test_w2v.shape[1], 1))\n",
    "\n",
    "# Créer et entraîner le modèle CNN\n",
    "model_cnn = model.create_cnn_model(input_shape=(X_train_cnn.shape[1], 1))\n",
    "model_cnn.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle\n",
    "evaluation.evaluer_modele(model_cnn, X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.4 Entraînement et évaluation du modèle LSTM\n",
    "\n",
    "# Créer et entraîner le modèle LSTM\n",
    "model_lstm = model.create_lstm_model(input_shape=(X_train_w2v.shape[1],))\n",
    "model_lstm.fit(X_train_w2v, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle\n",
    "evaluation.evaluer_modele(model_lstm, X_test_w2v, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.5 Entraînement et évaluation du modèle BERT\n",
    "\n",
    "# Créer et entraîner le modèle BERT\n",
    "model_bert, tokenizer = model.create_bert_model()\n",
    "\n",
    "# Tokenizer les tweets d'entraînement et de test\n",
    "X_train_bert = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
    "X_test_bert = tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors=\"tf\") 1 \n",
    "\n",
    "# Convertir les labels en tenseurs\n",
    "y_train_bert = tf.convert_to_tensor(y_train)\n",
    "y_test_bert = tf.convert_to_tensor(y_test)\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model_bert.fit(\n",
    "    x={\"input_ids\": X_train_bert[\"input_ids\"], \"attention_mask\": X_train_bert[\"attention_mask\"]},\n",
    "    y=y_train_bert,\n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "# Évaluer le modèle\n",
    "y_pred_bert = model_bert.predict(X_test_bert).logits\n",
    "y_pred_bert = np.argmax(y_pred_bert, axis=1)\n",
    "evaluation.evaluer_modele(model_bert,\n",
    "                          {\"input_ids\": X_test_bert[\"input_ids\"], \"attention_mask\": X_test_bert[\"attention_mask\"]},\n",
    "                          y_test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.6 Entraînement et évaluation du modèle USE\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Charger le modèle USE\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "# Encoder les tweets\n",
    "X_train_use = embed(X_train)\n",
    "X_test_use = embed(X_test)\n",
    "\n",
    "# Créer et entraîner le modèle USE\n",
    "model_use = model.create_use_model(input_shape=(X_train_use.shape[1],))\n",
    "model_use.fit(X_train_use, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle\n",
    "evaluation.evaluer_modele(model_use, X_test_use, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparaison des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Comparaison des modèles\n",
    "# Fonction pour comparer les modèles en utilisant les métriques d'évaluation\n",
    "def comparer_modeles(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Comparaison des modèles\n",
    "modeles = [model_baseline, model_mlp, model_cnn, model_lstm]\n",
    "noms_modeles = ['Régression Logistique', 'MLP', 'CNN', 'LSTM']\n",
    "y_preds = [model.predict(X_test_kbest) for model in modeles]\n",
    "\n",
    "# Calculer les métriques pour chaque modèle\n",
    "resultats = []\n",
    "for y_pred in y_preds:\n",
    "    resultats.append(comparer_modeles(y_test, y_pred))\n",
    "\n",
    "# Créer un DataFrame pour afficher les résultats\n",
    "comparaison = pd.DataFrame(resultats, columns=['Accuracy', 'Precision', 'Recall', 'F1-score'], index=noms_modeles)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(comparaison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
