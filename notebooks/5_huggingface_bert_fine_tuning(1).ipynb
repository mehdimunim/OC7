{"cells":[{"cell_type":"markdown","id":"7f366e52","metadata":{"id":"7f366e52"},"source":["# HuggingFace : BERT Fine-tuning\n","\n","In this notebook, we will fine-tune a pre-trained model to predict the sentiment of the tweets : [Fine-tune with TensorFlow](https://huggingface.co/docs/transformers/custom_datasets#finetune-with-tensorflow).\n","\n","We will compare this pre-trained local model to the baseline model from [1_baseline.ipynb](1_baseline.ipynb).\n","\n","In order to use GPU for training, we used Kaggle environment.\n","\n","\n","## Load project modules and data\n","\n","We will use basic python packages, and the [HuggingFace](https://huggingface.co/docs/transformers/quicktour) package to predict text sentiment.\n"]},{"cell_type":"code","source":[],"metadata":{"id":"BtfqAT62Zu-p"},"id":"BtfqAT62Zu-p","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"dc086279","metadata":{"execution":{"iopub.execute_input":"2022-01-28T10:39:39.717480Z","iopub.status.busy":"2022-01-28T10:39:39.715936Z","iopub.status.idle":"2022-01-28T10:39:53.939079Z","shell.execute_reply":"2022-01-28T10:39:53.939804Z","shell.execute_reply.started":"2022-01-28T10:25:21.385214Z"},"papermill":{"duration":14.234618,"end_time":"2022-01-28T10:39:53.940189","exception":false,"start_time":"2022-01-28T10:39:39.705571","status":"completed"},"tags":[],"id":"dc086279"},"outputs":[],"source":["from tqdm import tqdm\n","\n","# Maths modules\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","# Load data from CSV\n","df = pd.read_csv(\n","    \"training.1600000.processed.noemoticon.csv\",\n","    names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"],\n","    encoding=\"ISO-8859-1\",\n",")\n","\n","# Drop useless columns\n","df.drop(columns=[\"id\", \"date\", \"flag\", \"user\"], inplace=True)\n","\n","# Replace target values with labels\n","df.target.replace(\n","    {\n","        0: \"NEGATIVE\",\n","        2: \"NEUTRAL\",\n","        4: \"POSITIVE\",\n","    },\n","    inplace=True,\n",")\n","\n","df.target.replace(\n","    {\n","        \"NEGATIVE\": 0,\n","        \"POSITIVE\": 1,\n","    },\n","    inplace=True,\n",")\n","\n","# Sample data for development\n","TEXT_SAMPLE_SIZE = 1000000  # <= 0 for all\n","\n","# Sample data\n","if TEXT_SAMPLE_SIZE > 0:\n","    df = (\n","        df.groupby(\"target\", group_keys=False)\n","        .apply(\n","            lambda x: x.sample(\n","                n=int(TEXT_SAMPLE_SIZE / df[\"target\"].nunique()), random_state=42\n","            )\n","        )\n","        .reset_index(drop=True)\n","    )"]},{"cell_type":"markdown","id":"173f2757","metadata":{"id":"173f2757"},"source":["## Text preprocessing\n","\n","\n","The text is transformed to tensors with [AutoTokenizer](https://huggingface.co/docs/transformers/master/en/model_doc/auto#transformers.AutoTokenizer).\n"]},{"cell_type":"code","execution_count":null,"id":"b552ce33","metadata":{"execution":{"iopub.execute_input":"2022-01-28T10:39:53.972393Z","iopub.status.busy":"2022-01-28T10:39:53.971513Z","iopub.status.idle":"2022-01-28T10:47:28.496793Z","shell.execute_reply":"2022-01-28T10:47:28.497232Z"},"papermill":{"duration":454.546773,"end_time":"2022-01-28T10:47:28.497382","exception":false,"start_time":"2022-01-28T10:39:53.950609","status":"completed"},"tags":[],"colab":{"referenced_widgets":["42168ea73e894551b018701baae5a883","1d20835ad87540cca40dec45fde5c9d5","31fe34b645cf4205b40f88f1971a185a","47ce818ccdb448beabd6b1eed1bf2c34"]},"id":"b552ce33","outputId":"51ffd13e-5ccf-4ecc-cbc4-30daffdb6b5c"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42168ea73e894551b018701baae5a883","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d20835ad87540cca40dec45fde5c9d5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31fe34b645cf4205b40f88f1971a185a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47ce818ccdb448beabd6b1eed1bf2c34","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000000/1000000 [02:22<00:00, 7032.86it/s]\n","100%|██████████| 1000000/1000000 [02:20<00:00, 7106.50it/s]\n","100%|██████████| 1000000/1000000 [02:23<00:00, 6982.10it/s]\n"]}],"source":["# Tokenizers, Stemmers and Lemmatizers\n","from transformers import AutoTokenizer\n","\n","BERT_MODEL = \"bert-base-uncased\"  # \"vinai/bertweet-base\"\n","MAX_LENGTH = 50\n","\n","tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True)\n","\n","input_ids = np.asarray(\n","    [\n","        tokenizer(sent, max_length=MAX_LENGTH, padding=\"max_length\", truncation=True)[\n","            \"input_ids\"\n","        ]\n","        for sent in tqdm(df.text)\n","    ]\n",")\n","attention_mask = np.asarray(\n","    [\n","        tokenizer(sent, max_length=MAX_LENGTH, padding=\"max_length\", truncation=True)[\n","            \"attention_mask\"\n","        ]\n","        for sent in tqdm(df.text)\n","    ]\n",")\n","token_type_ids = np.asarray(\n","    [\n","        tokenizer(sent, max_length=MAX_LENGTH, padding=\"max_length\", truncation=True)[\n","            \"token_type_ids\"\n","        ]\n","        for sent in tqdm(df.text)\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"id":"7ee0a77f","metadata":{"execution":{"iopub.execute_input":"2022-01-28T10:47:30.606915Z","iopub.status.busy":"2022-01-28T10:47:30.605973Z","iopub.status.idle":"2022-01-28T10:47:31.495440Z","shell.execute_reply":"2022-01-28T10:47:31.494804Z"},"papermill":{"duration":1.965489,"end_time":"2022-01-28T10:47:31.495589","exception":false,"start_time":"2022-01-28T10:47:29.530100","status":"completed"},"tags":[],"id":"7ee0a77f"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","\n","# Train-test split\n","(\n","    texts_train,\n","    texts_test,\n","    input_ids_train,\n","    input_ids_test,\n","    attention_mask_train,\n","    attention_mask_test,\n","    token_type_ids_train,\n","    token_type_ids_test,\n","    labels_train,\n","    labels_test,\n",") = train_test_split(\n","    df.text.values,\n","    input_ids,\n","    attention_mask,\n","    token_type_ids,\n","    df.target.values,\n","    test_size=0.2,\n","    stratify=df.target.values,\n","    random_state=42,\n",")"]},{"cell_type":"markdown","id":"b4ad1fa4","metadata":{"id":"b4ad1fa4"},"source":["## Model fine-tuning\n","\n","We are going to fit the [TFAutoModelForSequenceClassification](https://huggingface.co/docs/transformers/master/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification) in order to adapt it to our dataset.\n"]},{"cell_type":"code","execution_count":null,"id":"a9c57f02","metadata":{"execution":{"iopub.execute_input":"2022-01-28T10:47:33.577906Z","iopub.status.busy":"2022-01-28T10:47:33.577022Z","iopub.status.idle":"2022-01-28T17:12:38.082342Z","shell.execute_reply":"2022-01-28T17:12:38.081859Z","shell.execute_reply.started":"2022-01-28T10:33:37.397450Z"},"papermill":{"duration":23105.535712,"end_time":"2022-01-28T17:12:38.082467","exception":false,"start_time":"2022-01-28T10:47:32.546755","status":"completed"},"tags":[],"colab":{"referenced_widgets":["47490a7132394557b65a89cb3e99d830"]},"id":"a9c57f02","outputId":"3021e8ac-7fb4-494a-dbbc-e1bcfaff76a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defining model...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47490a7132394557b65a89cb3e99d830","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2022-01-28 10:48:00.445844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:00.446928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:00.447582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:00.448433: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-01-28 10:48:00.449713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:00.450401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:00.451007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:04.730174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:04.730933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:04.731616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-28 10:48:04.732194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14941 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Compiling model...\n","Fitting model...\n"]},{"name":"stderr","output_type":"stream","text":["2022-01-28 10:48:08.923912: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","80000/80000 [==============================] - 5748s 72ms/step - loss: 0.4389 - binary_accuracy: 0.8235 - val_loss: 0.3765 - val_binary_accuracy: 0.8500\n","Epoch 2/10\n","80000/80000 [==============================] - 5723s 72ms/step - loss: 0.5091 - binary_accuracy: 0.8428 - val_loss: 0.4480 - val_binary_accuracy: 0.8487\n","Epoch 3/10\n","80000/80000 [==============================] - 5751s 72ms/step - loss: 0.4641 - binary_accuracy: 0.8516 - val_loss: 0.4500 - val_binary_accuracy: 0.8436\n","Epoch 4/10\n","80000/80000 [==============================] - 5756s 72ms/step - loss: 0.4057 - binary_accuracy: 0.8482 - val_loss: 0.4579 - val_binary_accuracy: 0.8421\n","Model: \"tf_bert_for_sequence_classification\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  109482240 \n","_________________________________________________________________\n","dropout_37 (Dropout)         multiple                  0         \n","_________________________________________________________________\n","classifier (Dense)           multiple                  1538      \n","=================================================================\n","Total params: 109,483,778\n","Trainable params: 109,483,778\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["from transformers import TFAutoModelForSequenceClassification\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.losses import BinaryCrossentropy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import BinaryAccuracy\n","\n","\n","# Define NN model\n","print(\"Defining model...\")\n","model = TFAutoModelForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=2)\n","\n","# compile NN network\n","print(\"Compiling model...\")\n","model.compile(\n","    loss=BinaryCrossentropy(),\n","    optimizer=Adam(learning_rate=2e-5),  # Value recommended by the Bert team\n","    metrics=BinaryAccuracy(),\n",")\n","\n","# fit NN model\n","print(\"Fitting model...\")\n","model.fit(\n","    [input_ids_train, attention_mask_train, token_type_ids_train],\n","    labels_train,\n","    epochs=10,\n","    batch_size=8,\n","    validation_split=0.2,\n","    callbacks=[\n","        EarlyStopping(monitor=\"val_loss\", patience=3),\n","    ],\n","    workers=4,\n","    use_multiprocessing=True,\n",")\n","\n","print(model.summary())"]},{"cell_type":"markdown","id":"610488e7","metadata":{"id":"610488e7"},"source":["## Results and evaluation\n","\n","We tried to fine-tune two different models, and we will compare the results : the standard [BERT](https://huggingface.co/docs/transformers/master/en/model_doc/bert) model, and the more adapted to english tweets [BERTweet](https://huggingface.co/docs/transformers/master/en/model_doc/bertweet) model.\n","\n","\n","### Vanilla BERT model : `bert-base-uncased`\n","\n","The model has been trained for ~6.5h on 1M on Kaggle with GPU accelerator : [oc-p7_bert_fine-tuning - Version 8 - 8-BERT-1M](https://www.kaggle.com/clementfleury/oc-p7-bert-fine-tuning/log?scriptVersionId=86383932).\n","\n","The model has more than 109M parameters, so the 1M tweets are probably not enough to train the model correctly.\n"]},{"cell_type":"code","execution_count":null,"id":"793ae072","metadata":{"execution":{"iopub.execute_input":"2022-01-28T17:15:37.908528Z","iopub.status.busy":"2022-01-28T17:15:37.907555Z","iopub.status.idle":"2022-01-28T17:25:56.104605Z","shell.execute_reply":"2022-01-28T17:25:56.103849Z","shell.execute_reply.started":"2022-01-28T10:39:15.169871Z"},"papermill":{"duration":708.203092,"end_time":"2022-01-28T17:25:56.104831","exception":false,"start_time":"2022-01-28T17:14:07.901739","status":"completed"},"tags":[],"id":"793ae072"},"outputs":[],"source":["y_pred = model.predict([input_ids_test, attention_mask_test, token_type_ids_test])\n","y_pred_proba = [float(x[1]) for x in tf.nn.softmax(y_pred.logits)]\n","y_pred_label = [0 if x[0] > x[1] else 1 for x in tf.nn.softmax(y_pred.logits)]"]},{"cell_type":"code","execution_count":null,"id":"2d2fb00b","metadata":{"execution":{"iopub.execute_input":"2022-01-28T17:28:55.833266Z","iopub.status.busy":"2022-01-28T17:28:55.832437Z","iopub.status.idle":"2022-01-28T17:28:56.231522Z","shell.execute_reply":"2022-01-28T17:28:56.230766Z","shell.execute_reply.started":"2022-01-28T10:39:15.171711Z"},"papermill":{"duration":90.145953,"end_time":"2022-01-28T17:28:56.231647","exception":false,"start_time":"2022-01-28T17:27:26.085694","status":"completed"},"tags":[],"id":"2d2fb00b","outputId":"9d13d147-0a6e-4ab7-bb7b-b27261224655"},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix : \n","[[17631 82369]\n"," [  415 99585]]\n","ROC AUC score :  0.883\n","Average Precision score :  0.822\n"]}],"source":["from sklearn.metrics import (\n","    confusion_matrix,\n","    roc_auc_score,\n","    average_precision_score,\n",")\n","\n","print(\"Confusion Matrix : \")\n","print(confusion_matrix(labels_test, y_pred_label))\n","\n","print(\"ROC AUC score : \", round(roc_auc_score(labels_test, y_pred_proba), 3))\n","\n","print(\n","    \"Average Precision score : \",\n","    round(average_precision_score(labels_test, y_pred_proba), 3),\n",")"]},{"cell_type":"code","execution_count":null,"id":"75a083ee","metadata":{"execution":{"iopub.execute_input":"2022-01-28T17:31:55.829197Z","iopub.status.busy":"2022-01-28T17:31:55.828196Z","iopub.status.idle":"2022-01-28T17:31:55.831408Z","shell.execute_reply":"2022-01-28T17:31:55.831812Z","shell.execute_reply.started":"2022-01-28T10:39:15.173568Z"},"papermill":{"duration":90.036532,"end_time":"2022-01-28T17:31:55.831947","exception":false,"start_time":"2022-01-28T17:30:25.795415","status":"completed"},"tags":[],"id":"75a083ee","outputId":"07e1596d-a22d-4a0d-f6e4-118893e7241b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Text :  one word: exhausted.  i swear to god my back has broken or somthing. I am in absolute AGONY. worst pain i've ever felt.\n","True sentiment :  0\n","Predicted sentiment :  0.436\n"]}],"source":["from random import randrange\n","\n","\n","idx = randrange(len(texts_test))\n","\n","print(\"Text : \", texts_test[idx])\n","print(\"True sentiment : \", labels_test[idx])\n","print(\"Predicted sentiment : \", round(y_pred_proba[idx], 3))"]},{"cell_type":"markdown","id":"09885aeb","metadata":{"id":"09885aeb"},"source":["The performances on the test dataset are slightly better than the baseline model, but not as good as other models :\n","- Average Precision = 0.82 (baseline = 0.73 , +12%)\n","- ROC AUC = 0.88 (baseline = 0.74 , +19%)\n","\n","But this model is really very biased towards the _POSITIVE_ class : it predicted **9.1 times** (baseline = 35% , -89%) more _POSITIVE_ (181954) messages than _NEGATIVE_ (18046).\n"]},{"cell_type":"markdown","id":"2e179eed","metadata":{"id":"2e179eed"},"source":["### English tweets adapted model : `vinai/bertweet-base`\n","\n","The model has been trained for ~11h on 1M on Kaggle with GPU accelerator : [oc-p7_bert_fine-tuning - Version 10 - 10-BERTweet-1M](https://www.kaggle.com/clementfleury/oc-p7-bert-fine-tuning/log?scriptVersionId=87009060).\n","\n","The model has more than 134M parameters, so the 1M tweets are probably not enough to train the model correctly.\n","\n","This run failed in the end because it reached Kaggle's maximum execution time, but the results are still available in the logs :\n","\n","````log\n","Confusion Matrix :\n","[[79351 20649]\n","[10016 89984]]\n","\n","ROC AUC score : 0.915\n","Average Precision score : 0.901\n","\n","Text : \"@Retrievergirl Clapton's is certainly one of the worlds greatest guitarists , and for me closely followed by Brian May\"\n","True sentiment : 1\n","Predicted sentiment : 0.542\n","````\n","\n","The performances on the test dataset are much better than the baseline model :\n","- Average Precision = 0.901 (baseline = 0.73 , +23%)\n","- ROC AUC = 0.915 (baseline = 0.74 , +24%)\n","\n","But this model is still quite biased towards the _POSITIVE_ class : it predicted 23% (baseline = 35% , -35%) more _POSITIVE_ (110633) messages than _NEGATIVE_ (89367).\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":24836.22298,"end_time":"2022-01-28T17:33:27.960505","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-01-28T10:39:31.737525","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}